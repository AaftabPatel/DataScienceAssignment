{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "raw",
      "source": "Aaftab Patel   IT-2K20-02   M.Tech(IT) - 5th semester   Data Science   Assignment",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**12: ASSOCIATION RULES**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. How to Mine Association Rules Using Python",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\nfrom mlxtend.frequent_patterns import apriori, association_rules\ndf = pd.read_csv('GroceryStoreDataSet.csv', names = ['products'], sep = ',')\ndf.head()\ndata = list(df[\"products\"].apply(lambda x:x.split(\",\") ))\ndata\n#Let's transform the list, with one-hot encoding\nfrom mlxtend.preprocessing import TransactionEncoder\na = TransactionEncoder()\na_data = a.fit(data).transform(data)\ndf = pd.DataFrame(a_data,columns=a.columns_)\ndf = df.replace(False,0)\ndf\n#set a threshold value for the support value and calculate the support value.\ndf = apriori(df, min_support = 0.2, use_colnames = True, verbose = 1)\ndf\n#Let's view our interpretation values using the Associan rule function.\ndf_ar = association_rules(df, metric = \"confidence\", min_threshold = 0.6)\ndf_ar",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.10/site-packages/pyolite/kernel.py:99: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  if self.interpreter.should_run_async(code):\n/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Processing 42 combinations | Sampling itemset size 3\n",
          "output_type": "stream"
        },
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    antecedents consequents  antecedent support  consequent support  support  \\\n0        (MILK)     (BREAD)                0.25                0.65      0.2   \n1       (SUGER)     (BREAD)                0.30                0.65      0.2   \n2  (CORNFLAKES)    (COFFEE)                0.30                0.40      0.2   \n3       (SUGER)    (COFFEE)                0.30                0.40      0.2   \n4       (MAGGI)       (TEA)                0.25                0.35      0.2   \n\n   confidence      lift  leverage  conviction  \n0    0.800000  1.230769    0.0375        1.75  \n1    0.666667  1.025641    0.0050        1.05  \n2    0.666667  1.666667    0.0800        1.80  \n3    0.666667  1.666667    0.0800        1.80  \n4    0.800000  2.285714    0.1125        3.25  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>antecedents</th>\n      <th>consequents</th>\n      <th>antecedent support</th>\n      <th>consequent support</th>\n      <th>support</th>\n      <th>confidence</th>\n      <th>lift</th>\n      <th>leverage</th>\n      <th>conviction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(MILK)</td>\n      <td>(BREAD)</td>\n      <td>0.25</td>\n      <td>0.65</td>\n      <td>0.2</td>\n      <td>0.800000</td>\n      <td>1.230769</td>\n      <td>0.0375</td>\n      <td>1.75</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(SUGER)</td>\n      <td>(BREAD)</td>\n      <td>0.30</td>\n      <td>0.65</td>\n      <td>0.2</td>\n      <td>0.666667</td>\n      <td>1.025641</td>\n      <td>0.0050</td>\n      <td>1.05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(CORNFLAKES)</td>\n      <td>(COFFEE)</td>\n      <td>0.30</td>\n      <td>0.40</td>\n      <td>0.2</td>\n      <td>0.666667</td>\n      <td>1.666667</td>\n      <td>0.0800</td>\n      <td>1.80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(SUGER)</td>\n      <td>(COFFEE)</td>\n      <td>0.30</td>\n      <td>0.40</td>\n      <td>0.2</td>\n      <td>0.666667</td>\n      <td>1.666667</td>\n      <td>0.0800</td>\n      <td>1.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(MAGGI)</td>\n      <td>(TEA)</td>\n      <td>0.25</td>\n      <td>0.35</td>\n      <td>0.2</td>\n      <td>0.800000</td>\n      <td>2.285714</td>\n      <td>0.1125</td>\n      <td>3.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "2. How to Apply the Confidence Difference Criterion Using R/Python",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport scipy.stats as st\n\n# define sample data\ngfg_data = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3,\n\t\t\t3, 4, 4, 5, 5, 5, 6, 7, 8, 10]\n\n# create 90% confidence interval\nst.t.interval(alpha=0.90, df=len(gfg_data)-1,\n\t\t\tloc=np.mean(gfg_data),\n\t\t\tscale=st.sem(gfg_data))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2.962098014195961, 4.837901985804038)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "3. How to Apply the Confidence Quotient Criterion Using R/Python",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport scipy.stats as st\n\n# define sample data\ngfg_data = np.random.randint(5, 10, 100)\n\n# create 90% confidence interval\n# for population mean weight\nst.norm.interval(alpha=0.90,\n\t\t\t\tloc=np.mean(gfg_data),\n\t\t\t\tscale=st.sem(gfg_data))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(6.752619934693425, 7.1873800653065745)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}